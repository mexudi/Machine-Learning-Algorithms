{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5f07740",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "The Random Forest algorithm is an ensemble of the Decision Trees algorithm. A Decision Tree model is generally trained using the Bagging Classifier. If you don’t want to use a bagging classifier algorithm to pass it through the Decision Tree Classification model, you can use a Random Forest algorithm as it is more convenient and better optimized for Decision Tree Classification. In this article, I will take you through the Random Forest algorithm in Machine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cf51738",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e4565d",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "Now, I will load the data, and split it into training and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13fa09fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X, y = make_moons(n_samples=500, noise=0.30, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed091cb",
   "metadata": {},
   "source": [
    "Now I will prepare the data using the bagging classifier and the decision tree classification model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "564546b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(splitter=\"random\", max_leaf_nodes=16, random_state=42),\n",
    "    n_estimators=500, max_samples=1.0, bootstrap=True, random_state=42)\n",
    "bag_clf.fit(X_train, y_train)\n",
    "y_pred = bag_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e9284c",
   "metadata": {},
   "source": [
    "## Random Forest Algorithm in Machine Learning\n",
    "\n",
    "With a very few parameters, a RandomForestClassifier uses all the hyperparameters of a Decision Tree Classification model and bagging classifier algorithm. Now let’s see how we can do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42ce309b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.976"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, random_state=42)\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rnd_clf.predict(X_test)\n",
    "np.sum(y_pred == y_pred_rf) / len(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5118091",
   "metadata": {},
   "source": [
    "The RandomForestClassifier algorithm works by introducing extra randomness while producing decision trees. Instead of searching for the best features, it works by searching for the best features among the random sets of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e15aedf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal length (cm) 0.11249225099876375\n",
      "sepal width (cm) 0.02311928828251033\n",
      "petal length (cm) 0.4410304643639577\n",
      "petal width (cm) 0.4233579963547682\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, random_state=42)\n",
    "rnd_clf.fit(iris[\"data\"], iris[\"target\"])\n",
    "for name, score in zip(iris[\"feature_names\"], rnd_clf.feature_importances_):\n",
    "    print(name, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "059877e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.11249225, 0.02311929, 0.44103046, 0.423358  ])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c483301",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
